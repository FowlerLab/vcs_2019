## ndatadf (nls info)
ndata = unique(uP_nls_human[,c('uniprotid', 'text', 'NLS_start', 'NLS_end')])
colnames(ndata) = c('uniprotid', 'text', 'NLS_start', 'NLS_end')
ndata$NLS_seq = sapply(seq(1,nrow(ndata)), function(i) {
prot_seq = unlist(strsplit(pdata[ndata[i,'uniprotid'],'aa'], ''))
nls_seq = paste(prot_seq[ndata[i,'NLS_start']:ndata[i,'NLS_end']], collapse='')
return(nls_seq)
})
ndata = ndata[order(ndata$uniprotid),]
ndata = bind_rows(lapply(unique(ndata$uniprotid), function(uniprotid) {
subdf = ndata[which(ndata$uniprotid == uniprotid),]
subdf = subdf[order(subdf$NLS_start),]
subdf$NLS_name = sapply(seq(1, nrow(subdf)), function(i) paste0(uniprotid, '_', i))
return(subdf)
}))
ndata$monopartite_nls = sapply(seq(1, nrow(ndata)), function(i) {
check_for_motif(aa = pdata[which(pdata$uniprotid == ndata[i,'uniprotid']),'aa'],
NLS_start = ndata[i,'NLS_start'],
NLS_end = ndata[i,'NLS_end'],
motif = 'K,K/R,X,K/R')})
ndata$prop_KR = sapply(seq(1, nrow(ndata)), function(i) {
return(sum(unlist(strsplit(ndata[i,'NLS_seq'], '')) %in% c('K','R')) / nchar(ndata[i,'NLS_seq']))
})
ndata$num_KR = sapply(seq(1, nrow(ndata)), function(i) {
return(sum(unlist(strsplit(ndata[i,'NLS_seq'], '')) %in% c('K','R')))
})
head(pdata)
head(ndata)
# Chunk 16
annotation_df_uniprot <- compute_prediction_df(pdata, score_matrix, ndata)
print(paste0('Number of proteins:', length(unique(annotation_df_uniprot[,'seq_name']))))
# Chunk 17
cross_validation_test <- function(scrambled, training_df, ndata, regression_function, pick_top_rank_only) {
# calculate ranks based on score
print('Calculating ranks for NLSs based on pssm score (even weights)..')
ndata_ranks = get_min_ranks_NLS(training_df, ndata, 'pssm_score')
# create and return the dataframe with cross validation rank metrics
final_output = lapply(unique(names(scrambled)), function(chunk_name) {
print(paste0('Running chunk ', chunk_name, '..'))
train = training_df[which(training_df$seq_name %in% scrambled[which(names(scrambled) != chunk_name)]),] # train = those not in this test chunk
test = training_df[which(training_df$seq_name %in% scrambled[which(names(scrambled) == chunk_name)]),] # test = those in the test chunk
# find training sequences
print('Finding training sequences..')
if(pick_top_rank_only) { # take all windows that overlap with the NLS AND are ranked 1 amongst all windows in the protein
toprank = ndata_ranks[which(ndata_ranks$rank == 1),]
} else { # take the top scoring window for each NLS
toprank = ndata_ranks[which(ndata_ranks$uniprotid.x %in% train$seq_name),]
}
# annotate training dataset with the putative NLS's
train$seq_name = as.character(train$seq_name)
train = merge(train,
toprank[,c('uniprotid.x', 'motif_start', 'rank')],
by.x = c('seq_name', 'start_pos'),
by.y = c('uniprotid.x', 'motif_start'),
all.x = T)
train$likely_monopartite = F
train[which(!is.na(train$rank)),'likely_monopartite'] = T
train_median_overlap_score = median(train[which(train$likely_monopartite),'prop_overlap'])
# generate and test model
print('Generating and testing model..')
glm_pos <- regression_function(data = train)
coeffs = glm_pos$coefficients
# get the ranks using the training data-derived glm
test$predicted_glm = stats::predict(glm_pos, test)
ranks_predicted = get_min_ranks_NLS(test, ndata, 'predicted_glm')
output = c(prop_toprank_glm = sum(ranks_predicted$rank == 1) / nrow(ranks_predicted),
prop_topfive_glm = sum(ranks_predicted$rank < 6) / nrow(ranks_predicted),
test_median_overlap_glm = median(ranks_predicted$prop_overlap))
names(output) = c('prop_toprank_glm', 'prop_topfive_glm', 'test_median_overlap_glm')
# retrieve the scores of the hits and the misses
test$likely_monopartite = F
test[which(!is.na(test$rank)),'likely_monopartite'] = T
predictions_df = test[,c('likely_monopartite', 'predicted_glm')]
output = list(c(output, coeffs), predictions_df, glm_pos)
return(output)
})
# reformat the output
final_output_df = lapply(final_output, function(i) i[[1]])
#final_output_vals = lapply(final_output, function(i) i[[2]])
names(final_output_df) = sapply(seq(1, length(unique(names(scrambled)))), function(n) paste0('chunk_', n)) # need names for bind_rows
#names(final_output_vals) = sapply(seq(1, length(unique(names(scrambled)))), function(n) paste0('chunk_', n))
final_output_df = bind_rows(final_output_df)
final_output_df = t(final_output_df) # make each row a chunk
colnames(final_output_df) = c('prop_toprank_glm', 'prop_topfive_glm', 'test_median_overlap_glm', names(final_output[[1]][[3]]$coefficients))
# get the toprank of all motifs
toprank = ndata_ranks[which(ndata_ranks$uniprotid.x %in% training_df$seq_name),]
# return the full model
training_df = merge(training_df,
toprank[,c('uniprotid.x', 'motif_start', 'rank')],
by.x = c('seq_name', 'start_pos'),
by.y = c('uniprotid.x', 'motif_start'),
all.x = T)
training_df$likely_monopartite = F
training_df[which(!is.na(training_df$rank)),'likely_monopartite'] = T
glm_pos_all <- regression_function(data = training_df)
to_return = list(as.data.frame(final_output_df),
#final_output_vals,
glm_pos_all)
names(to_return) = c('summary',
#'hpa_data_scores',
'model_all_data')
return(to_return)
}
# scramble uniprot ids, then split the data into 8 chunks
uPids = as.character(unique(annotation_df_uniprot$seq_name))
scrambled = sample(uPids, size = length(uPids), replace = F, set.seed(24))
names(scrambled) = cut(seq(1, length(scrambled)), 8)
# define the original and the position-wise function
glm_original <- function(data) {
glm(likely_monopartite ~ pssm_score,
data = data
)
}
glm_position_based <- function(data) {
glm(likely_monopartite ~ pos1 + pos2 + pos3 + pos4 + pos5 + pos6 + pos7 + pos8 + pos9 + pos10 + pos11,
data = data
)
}
# load data
#annotation_df_uniprot <- read.csv('uniprot_nls_db_scores.csv')
# prep scrambled data
uPids = as.character(unique(annotation_df_uniprot$seq_name))
scrambled = sample(uPids, size = length(uPids), replace = F)
names(scrambled) = cut(seq(1, length(scrambled)), 8)
# apply each function the cross validation procedure
glm_original_XV = cross_validation_test(scrambled, annotation_df_uniprot, ndata, glm_original, pick_top_rank_only = F)
glm_position_based_XV = cross_validation_test(scrambled, annotation_df_uniprot, ndata, glm_position_based, pick_top_rank_only = F)
# save the models
#saveRDS(glm_original_XV$model_all_data, 'unweighted_model_all_data.RDS')
#saveRDS(glm_position_based_XV$model_all_data, 'position_weighted_model_all_data.RDS')
# Chunk 18
scores$weight = sapply(scores$aa_pos, function(x) {
glm_position_based_XV$model_all_data$coefficients[paste0('pos', x)]
})
scores$weighted_aa_pref = scores$aa_pref * scores$weight
ggplot(scores, aes(x = aa_pos, y = mt_aa, fill = weighted_aa_pref)) +
geom_tile(color = 'black', size = 0.5) +
scale_fill_viridis_c() +
theme_classic() +
theme(axis.text=element_text(size=14),
axis.title=element_text(size=16),
legend.title = element_text(size = 16),
legend.text = element_text(size = 14),
legend.position = 'bottom') +
ylab('Mutant Amino Acid') +
xlab('Position') +
labs(fill="Weighted\nPreference")
ggsave('preference_matrix_weighted.png', width = 3.5, height = 6, dpi = 900)
# Chunk 19
# compare the performance of the summary dataframes
glm_original_XV$summary$model = 'Unweighted'
glm_position_based_XV$summary$model = 'Position-weighted'
to_plot = melt(rbind(glm_original_XV$summary[,c('prop_toprank_glm', 'prop_topfive_glm', 'model')],
glm_position_based_XV$summary[,c('prop_toprank_glm', 'prop_topfive_glm', 'model')]),
id.vars = 'model')
to_plot$model = factor(to_plot$model, levels = c('Unweighted', 'Position-weighted'), ordered = T)
ggplot(to_plot, aes(x = interaction(model, variable), color = model, group = variable, y = value)) + geom_point(size = 2, alpha = 0.5) + stat_summary(alpha = 1, color = 'black', size = 1)  + ylim(0,1) + theme(axis.text.x=element_text(angle = 45, hjust = 1)) + ylab('Proportion top-ranked 11mers')
# apply the final model to the original 4 NLS's
scores_monopartite_df$position_weighted_score = stats::predict(glm_position_based_XV$model_all_data, scores_monopartite_df)
# plot proteins
plot_specific(scores_monopartite_df, unique(scores_monopartite_df$seq_name
), ndata_monopartite, 1, 'position_weighted_score')
get_min_ranks_NLS(scores_monopartite_df, ndata_monopartite, 'position_weighted_score')
# look at position weights
glm_position_based_XV$model_all_data$coefficients
# Chunk 20
# apply to training data
annotation_df_uniprot$position_weighted_score = stats::predict(glm_position_based_XV$model_all_data, annotation_df_uniprot)
# do a precision recall curve for many possible bounds
precision_recall_trainingdata = as.data.frame(t(sapply(seq(min(annotation_df_uniprot$position_weighted_score), max(annotation_df_uniprot$position_weighted_score), length.out = 1000), function(val) {
TP = sum(annotation_df_uniprot$any_overlap & (annotation_df_uniprot$position_weighted_score > val))
TPFP = sum((annotation_df_uniprot$position_weighted_score > val))
FN = sum(!(ndata$NLS_name %in% annotation_df_uniprot[which(annotation_df_uniprot$position_weighted_score > val),'NLS_name']))
out = c(val, TP / TPFP, TP / (TP + FN))
names(out) = c('cutoff', 'precision', 'recall')
return(out)
})))
# remove NaN
precision_recall_trainingdata = precision_recall_trainingdata[which(!apply(precision_recall_trainingdata, 1, function(x) any(is.na(x)))),]
# designate the dataset and save
precision_recall_trainingdata$data = 'uniprot_training_data'
# Chunk 21
# hybrid dataset from Lin et al.
ndata_lin <- read.csv(file = '../data/2013-Lin_ST2.csv', stringsAsFactors = F)
ndata_lin$organism = sapply(ndata_lin$UniProtKB.ID, function(s) unlist(strsplit(s, "_"))[[2]])
# filter dataset and add human sequences
ndata_lin <- ndata_lin[which(ndata_lin$organism == 'HUMAN'),]
# get uniprot ids
## fasta file is from pasting the first column of the lin_ST2 dataframe into uniprot
human_pdata_lin = sapply(bio3d::read.fasta('../data/2013-Lin_ST2_UNIPROT.fasta')[[1]], function(x) unlist(strsplit(x, '_'))[[2]] == 'HUMAN')
# get proteome sequences
pdata_lin = seqinr::read.fasta(file = '../data/2013-Lin_ST2_UNIPROT.fasta', seqtype='AA', as.string=T)
pdata_lin = data.frame(UniProtKB.ID = sapply(names(pdata_lin), function(x) {unlist(strsplit(x, '\\|'))[[3]]}),
uniprotid = sapply(names(pdata_lin), function(x) {unlist(strsplit(x, '\\|'))[[2]]}),
aa = sapply(pdata_lin, function(x) x[[1]]),
stringsAsFactors = F)
pdata_lin = pdata_lin[which(human_pdata_lin),]
colnames(pdata_lin) <- c('UniProtKB.ID', 'uniprotid', 'aa')
# remove any data in the training data
pdata_lin <- pdata_lin[which(!(pdata_lin$uniprotid %in% pdata$uniprotid)),]
# check for missing sequences
ndata_lin[which((!ndata_lin$UniProtKB.ID %in% pdata_lin$UniProtKB.ID)),'UniProtKB.ID'] # this protein is not found when you search for it in NLSdb..
ndata_lin <- ndata_lin[which((ndata_lin$UniProtKB.ID %in% pdata_lin$UniProtKB.ID)),] # .. so we filter it out
ndata_lin <- merge(ndata_lin, unique(pdata_lin[,c('UniProtKB.ID', 'uniprotid')]), by='UniProtKB.ID')
ndata_lin$NLS_seq <- sapply(seq(1, nrow(ndata_lin)), function(i) {
NLS_start = ndata_lin[i,'Start']
NLS_end = ndata_lin[i,'Stop']
NLS_seq = substr(pdata_lin[which(pdata_lin$UniProtKB.ID == ndata_lin[i,'UniProtKB.ID']),'aa'], NLS_start, NLS_end)
return(NLS_seq)
})
ndata_lin$NLS_name = unlist(sapply(unique(ndata_lin$uniprotid), function(uPid) {
subdf = ndata_lin[which(ndata_lin$uniprotid == uPid),] # grab all NLS with matching uPid
row.names(subdf) = seq(1, nrow(subdf)) # reset row names
output = sapply(row.names(subdf), function(i) paste0(uPid, '_', i))
}))
# apply to the prediction pipeline
colnames(ndata_lin) <- c('UniProtKB.ID', 'NLS_start', 'NLS_end', 'PMID', 'organism', 'uniprotid', 'motif', 'NLS_name')
colnames(pdata_lin) <- c('UniProtKB.ID', 'uniprotid', 'aa')
apply(pdata_lin, 1, function(x) {
write(paste0('>',x['uniprotid']), file='pdata_lin.fasta', append=T)
write(x['aa'], file='pdata_lin.fasta', append=T)
})
test_annotated <- compute_prediction_df(ndata = ndata_lin, pdata = pdata_lin, score_matrix = score_matrix)
# Chunk 22
# use the model to predict NLS
test_annotated$position_weighted_score = stats::predict(glm_position_based_XV$model_all_data, test_annotated)
# get precision and recall for lin dataset
# do a precision recall curve for many possible bounds
## raw scores
precision_recall_test = as.data.frame(t(sapply(seq(min(test_annotated$position_weighted_score), max(test_annotated$position_weighted_score), length.out = 1000), function(val) {
TP = sum(test_annotated$any_overlap & (test_annotated$position_weighted_score > val))
TPFP = sum((test_annotated$position_weighted_score > val))
FN = sum(!(ndata_lin$NLS_name %in% test_annotated[which(test_annotated$position_weighted_score > val),'NLS_name']))
out = c(val, TP / TPFP, TP / (TP + FN))
names(out) = c('cutoff', 'precision', 'recall')
return(out)
})))
precision_recall_test = precision_recall_test[which(!apply(precision_recall_test, 1, function(x) any(is.na(x)))),]
# find high confidence (precision ~0.9) and candidate (~ precision 0.50) NLS cutoffs
high_confidence = min(precision_recall_test[which(abs(0.9 - precision_recall_test$precision) == min(abs(0.9 - precision_recall_test$precision))),'cutoff'])
candidate = min(precision_recall_test[which(abs(0.75 - precision_recall_test$recall) == min(abs(0.75 - precision_recall_test$recall))),'cutoff'])
# plot comparison
ggplot(precision_recall_test, aes(x = recall, y = precision)) + geom_line() + theme_classic() + geom_point(x = 0.23, y = 0.87, color = 'black') + geom_point(x = 0.63, y = 0.38, color = 'black')
# Chunk 23
# load predictions and change column names
lin_nls_seq_predictions = read.csv('../data/seqNLS_predictions.csv', stringsAsFactors = F)
colnames(lin_nls_seq_predictions) = c('uniprotid', 'motif', 'start_pos', 'end_pos', 'nlsseq_score')
# calculate overlap
prop_overlap = as.data.frame(t(apply(lin_nls_seq_predictions, 1, function(row) {
# subset ndata on the uniprotid of the row
ndata_subset = ndata_lin[which(ndata_lin['uniprotid'] == row['uniprotid']),]
# check whether there is any overlap between the called NLS and any of the annotated NLSs
overlaps = apply(ndata_subset, 1, function(candidate_NLS) calculate_overlap(start_NLS = as.numeric(candidate_NLS['NLS_start']),
end_NLS = as.numeric(candidate_NLS['NLS_end']),
start_pos = as.numeric(row['start_pos']),
end_pos = as.numeric(row['end_pos'])))
if(max(overlaps) != 0) {
return(c(max(overlaps), ndata_subset[which(overlaps == max(overlaps)),'NLS_name'][[1]])) }
else {return(c(0, 'none'))} })), stringsAsFactors = F)
colnames(prop_overlap) = c('prop_overlap', 'NLS_name')
lin_nls_seq_predictions = cbind(lin_nls_seq_predictions, prop_overlap)
lin_nls_seq_predictions$any_overlap = 0
lin_nls_seq_predictions[which(lin_nls_seq_predictions$prop_overlap > 0),'any_overlap'] = 1
# determine the precision and recall of the nlsseq predictions
precision_recall_nlsseq = as.data.frame(t(sapply(seq(min(lin_nls_seq_predictions$nlsseq_score), max(lin_nls_seq_predictions$nlsseq_score), length.out = 100), function(val) {
TP = sum(lin_nls_seq_predictions$any_overlap & (lin_nls_seq_predictions$nlsseq_score > val))
TPFP = sum((lin_nls_seq_predictions$nlsseq_score > val))
FN = sum(!(ndata_lin$NLS_name %in% lin_nls_seq_predictions[which(lin_nls_seq_predictions$nlsseq_score > val),'NLS_name']))
out = c(val, TP / TPFP, TP / (TP + FN))
names(out) = c('cutoff', 'precision', 'recall')
return(out)
})))
# remove na
precision_recall_nlsseq = precision_recall_nlsseq[which(!apply(precision_recall_nlsseq, 1, function(x) any(is.na(x)))),]
precision_recall_nlsseq$data = 'linetal_nlsseq'
# Chunk 24
parse_tradamus_out <- function(filename) {
fileend = unlist(strsplit(filename, '_'))[[3]]
cutoff = as.numeric(unlist(strsplit(fileend, '.out'))[[1]])
con <- file(paste0(filename), "rt")
df = read.csv(con, sep = '\t', header = F)
df = df[which(sapply(df[,1], function(x) unlist(strsplit(as.character(x), ' '))[[1]] != 'Finished')),]
df = df[1:(nrow(df)-6),]
colnames(df) = c('uniprotid', 'cutoff_type', 'cutoff', 'start_pos', 'end_pos', 'motif')
return(df)
}
nlstradamus_predictions <- parse_tradamus_out('../data/pdatalin_nlstradamus_0.01.out')
prop_overlap = as.data.frame(t(apply(nlstradamus_predictions, 1, function(row) {
# subset ndata on the uniprotid of the row
ndata_subset = ndata_lin[which(ndata_lin['uniprotid'] == row['uniprotid']),]
# check whether there is any overlap between the called NLS and any of the annotated NLSs
overlaps = apply(ndata_subset, 1, function(candidate_NLS) calculate_overlap(start_NLS = as.numeric(candidate_NLS['NLS_start']),
end_NLS = as.numeric(candidate_NLS['NLS_end']),
start_pos = as.numeric(row['start_pos']),
end_pos = as.numeric(row['end_pos'])))
if(max(overlaps) != 0) {
return(c(max(overlaps), ndata_subset[which(overlaps == max(overlaps)),'NLS_name'][[1]])) }
else {return(c(0, 'none'))} })), stringsAsFactors = F)
colnames(prop_overlap) = c('prop_overlap', 'NLS_name')
nlstradamus_predictions = cbind(nlstradamus_predictions, prop_overlap)
nlstradamus_predictions$any_overlap = 0
nlstradamus_predictions[which(nlstradamus_predictions$prop_overlap > 0),'any_overlap'] = 1
# determine the precision and recall of the nlstradamus predictions
precision_recall_nlstradamus = as.data.frame(t(sapply(seq(min(nlstradamus_predictions$cutoff), max(nlstradamus_predictions$cutoff), length.out = 100), function(val) {
TP = sum(nlstradamus_predictions$any_overlap & (nlstradamus_predictions$cutoff > val))
TPFP = sum((nlstradamus_predictions$cutoff > val))
FN = sum(!(ndata_lin$NLS_name %in% nlstradamus_predictions[which(nlstradamus_predictions$cutoff > val),'NLS_name']))
out = c(val, TP / TPFP, TP / (TP + FN))
names(out) = c('cutoff', 'precision', 'recall')
return(out)
})))
# remove na
precision_recall_nlstradamus = precision_recall_nlstradamus[which(!apply(precision_recall_nlsseq, 1, function(x) any(is.na(x)))),]
precision_recall_nlstradamus$data = 'nlstradamus'
# Chunk 25
canonical_ndata_lin = bind_rows(lapply(pdata_lin$uniprotid, function(x) {
aa = pdata_lin[which(pdata_lin$uniprotid == x),'aa']
split_aa = strsplit(aa, '')
hits = sapply(seq(1, (nchar(aa) - 3)), function(y) {
to_check = paste0(unlist(split_aa)[y:(y+3)])
check_for_motif(aa = to_check,
NLS_start = 1,
NLS_end = 4,
motif = 'K,K/R,X,K/R')})
out_df = data.frame(uniprotid = x,
start_pos = seq(1, (nchar(aa) - 3)),
end_pos = seq(4, (nchar(aa))),
hit = hits)
}))
prop_overlap = as.data.frame(t(apply(canonical_ndata_lin, 1, function(row) {
# subset ndata on the uniprotid of the row
ndata_subset = ndata_lin[which(ndata_lin['uniprotid'] == row['uniprotid']),]
# check whether there is any overlap between the called NLS and any of the annotated NLSs
overlaps = apply(ndata_subset, 1, function(candidate_NLS) calculate_overlap(start_NLS = as.numeric(candidate_NLS['NLS_start']),
end_NLS = as.numeric(candidate_NLS['NLS_end']),
start_pos = as.numeric(row['start_pos']),
end_pos = as.numeric(row['end_pos'])))
if(max(overlaps) != 0) {
return(c(max(overlaps), ndata_subset[which(overlaps == max(overlaps)),'NLS_name'][[1]])) }
else {return(c(0, 'none'))} })), stringsAsFactors = F)
colnames(prop_overlap) = c('prop_overlap', 'NLS_name')
canonical_ndata_lin = cbind(canonical_ndata_lin, prop_overlap)
canonical_ndata_lin$any_overlap = 0
canonical_ndata_lin[which(canonical_ndata_lin$prop_overlap > 0),'any_overlap'] = 1
TP = sum(canonical_ndata_lin$any_overlap & (canonical_ndata_lin$hit))
TPFP = sum((canonical_ndata_lin$hit))
FN = sum(!(ndata_lin$NLS_name %in% canonical_ndata_lin[which(canonical_ndata_lin$hit),'NLS_name']))
out = c(TRUE, TP / TPFP, TP / (TP + FN))
names(out) = c('cutoff', 'precision', 'recall')
print(out)
# Chunk 26
# plot
precision_recall_test$data = 'our_model'
all_predictors <- rbind(precision_recall_test, precision_recall_nlsseq, precision_recall_nlstradamus)
ggplot(all_predictors, aes(x = recall, y = precision)) +
geom_line(aes(color = data), size = 1) +
theme_classic() +
theme(axis.text=element_text(size=14),
axis.title=element_text(size=16),
axis.text.x=element_text(angle = 45, hjust = 1)) +
ylab('Precision') +
xlab('Recall') +
guides(color = F, linetype = F) +
scale_y_continuous(breaks=seq(0, 1, 0.25), limits = c(0, 1.1)) +
scale_x_continuous(breaks=seq(0, 1, 0.25), limits = c(0, 1.1)) +
scale_color_manual(values = c('#000000','#999999', '#d73027'))
ggsave('F3D.png', dpi= 900, width = 2.75, height = 2.75)
save.image('temp1.RData')
hpa_subcell <- read.csv('../data/aal3321_Thul_SM_table_S6.csv')
hpa_subcell$Uniprot = as.character(hpa_subcell$Uniprot)
nuc_loc = c('Nucleus', 'Nucleoplasm', 'Nuclear.bodies', 'Nuclear.speckles', 'Nucleoli', "Nucleoli..Fibrillar.center.")
hpa_subcell$any_nucleus = apply(hpa_subcell[,nuc_loc], 1,
function(row) {
# if all values are 0, return 0
if(all(row == 0)) { return(F) } else {return(T)}
})
# get columns of interest
hpa_data = hpa_subcell[which(hpa_subcell$any_nucleus),c(1,2,3)]
# make a dataframe and retrieve sequences using the fasta files of the human proteome
hpa_data = merge(hpa_subcell[,c('ENSG','Gene','Uniprot')], proteome_df, by.x = 'Uniprot', by.y = 'uniprotid')
# remove rows for which a sequence could not be found
colnames(hpa_data) = c('uniprotid', 'ENSG', 'Gene', 'aa')
hpa_data$aa = unlist(hpa_data$aa)
hpa_data = hpa_data[which(!is.na(hpa_data$aa)),]
# remove rows containing any non-canonical amino acids (e.g. U)
passing_rows = which(sapply(hpa_data$aa, function(aa) all(unlist(strsplit(aa, '')) %in% c('R', 'H', 'K', 'D', 'E', 'S', 'T', 'N', 'Q', 'C', 'G', 'P', 'A', 'V', 'I', 'L', 'M', 'F', 'Y', 'W'))))
hpa_data = hpa_data[passing_rows,]
# make predictions
hpa_data_prediction_df <- compute_prediction_df(pdata = hpa_data, score_matrix = score_matrix, ndata = NULL)
hpa_data_prediction_df <- merge(hpa_data_prediction_df, hpa_data[,c('uniprotid', 'Gene')], by.x = 'seq_name', by.y = 'uniprotid')
hpa_data_prediction_df$position_weighted_score = stats::predict(glm_position_based_XV$model_all_data, hpa_data_prediction_df)
# add high confidence vs. candidate NLS
hpa_data_prediction_df$prediction = '-'
hpa_data_prediction_df[which(hpa_data_prediction_df$position_weighted_score > candidate),'prediction'] = 'Candidate NLS'
hpa_data_prediction_df[which(hpa_data_prediction_df$position_weighted_score > high_confidence),'prediction'] = 'High confidence NLS'
# for each, designate as being noncanonical or not
## first, need to modify the annotation to include the sequence and rerun..!!
hpa_data_prediction_df$canonical_nls = NA
hpa_data_prediction_df[which(hpa_data_prediction_df$prediction != '-'),'canonical_nls'] = sapply(hpa_data_prediction_df[which(hpa_data_prediction_df$prediction != '-'),'motif'], function(x) check_for_motif(aa = x ,
NLS_start = 1,
NLS_end = 11,
motif = 'K,K/R,X,K/R'))
hpa_data_prediction_df_nls_candidates = hpa_data_prediction_df[which(hpa_data_prediction_df$prediction != '-'),]
sum(hpa_data_prediction_df_nls_candidates$prediction == 'Candidate NLS')
sum(hpa_data_prediction_df_nls_candidates$prediction == 'High confidence NLS')
sum(hpa_data_prediction_df_nls_candidates$prediction == 'High confidence NLS' & !(hpa_data_prediction_df_nls_candidates$canonical_nls))
sum(hpa_data_prediction_df_nls_candidates$prediction == 'Candidate NLS' & !(hpa_data_prediction_df_nls_candidates$canonical_nls))
write.csv(x = hpa_data_prediction_df_nls_candidates, file = 'ST3.csv')
save.image('temp2.RData')
high_confidence
candidate
nrow(hpa_data)
head(hpa_data)
hpa_subcell <- read.csv('../data/aal3321_Thul_SM_table_S6.csv')
hpa_subcell$Uniprot = as.character(hpa_subcell$Uniprot)
nuc_loc = c('Nucleus', 'Nucleoplasm', 'Nuclear.bodies', 'Nuclear.speckles', 'Nucleoli', "Nucleoli..Fibrillar.center.")
cyto_loc = c('Cytosol', 'Cytoplasmic.bodies')
all_locs = colnames(hpa_subcell)[4:32]
not_nuc_cyto = all_locs[which(!(all_locs %in% union(nuc_loc, cyto_loc)))]
hpa_subcell$localization = apply(hpa_subcell[,4:32], 1,
function(row) {
# annotate if only nuclear
if(any(row[nuc_loc]) & !any(row[not_nuc_cyto]) & !any(row[ cyto_loc])){return('only_nuclear')} else {
# annotate if only cytoplasmic
if(!any(row[nuc_loc]) & !any(row[not_nuc_cyto]) & any(row[ cyto_loc])){return('only_cytoplasmic')} else {
return('other')
}
}
})
# make a dataframe and retrieve sequences using the fasta files of the human proteome
hpa_data = merge(hpa_subcell[which(hpa_subcell$localization %in% c('only_cytoplasmic', 'only_nuclear')),c('ENSG','Gene','Uniprot','localization')], proteome_df, by = 'Uniprot')
# remove rows containing any non-canonical amino acids (e.g. U)
passing_rows = which(sapply(hpa_data$aa, function(aa) all(unlist(strsplit(aa, '')) %in% c('R', 'H', 'K', 'D', 'E', 'S', 'T', 'N', 'Q', 'C', 'G', 'P', 'A', 'V', 'I', 'L', 'M', 'F', 'Y', 'W'))))
hpa_data = hpa_data[passing_rows,]
colnames(hpa_data) = c('uniprotid', 'ENSG', 'Gene', 'localization', 'aa')
# make predictions
hpa_data_prediction_df <- compute_prediction_df(pdata = hpa_data, score_matrix = score_matrix, ndata = NULL)
hpa_subcell <- read.csv('../data/aal3321_Thul_SM_table_S6.csv')
hpa_subcell$Uniprot = as.character(hpa_subcell$Uniprot)
nuc_loc = c('Nucleus', 'Nucleoplasm', 'Nuclear.bodies', 'Nuclear.speckles', 'Nucleoli', "Nucleoli..Fibrillar.center.")
cyto_loc = c('Cytosol', 'Cytoplasmic.bodies')
all_locs = colnames(hpa_subcell)[4:32]
not_nuc_cyto = all_locs[which(!(all_locs %in% union(nuc_loc, cyto_loc)))]
hpa_subcell$localization = apply(hpa_subcell[,4:32], 1,
function(row) {
# annotate if only nuclear
if(any(row[nuc_loc]) & !any(row[not_nuc_cyto]) & !any(row[ cyto_loc])){return('only_nuclear')} else {
# annotate if only cytoplasmic
if(!any(row[nuc_loc]) & !any(row[not_nuc_cyto]) & any(row[ cyto_loc])){return('only_cytoplasmic')} else {
return('other')
}
}
})
# make a dataframe and retrieve sequences using the fasta files of the human proteome
hpa_data = merge(hpa_subcell[which(hpa_subcell$localization %in% c('only_cytoplasmic', 'only_nuclear')),c('ENSG','Gene','Uniprot','localization')], proteome_df, by = 'Uniprot')
head(hpa_data)
# make a dataframe and retrieve sequences using the fasta files of the human proteome
hpa_data = merge(hpa_subcell[which(hpa_subcell$localization %in% c('only_cytoplasmic', 'only_nuclear')),c('ENSG','Gene','uniprotid','localization')], proteome_df, by.x = 'uniprotid', by.y = 'Uniprot')
head(hpa_subcell)
# make a dataframe and retrieve sequences using the fasta files of the human proteome
hpa_data = merge(hpa_subcell[which(hpa_subcell$localization %in% c('only_cytoplasmic', 'only_nuclear')),c('ENSG','Gene','uniprotid','localization')], proteome_df, by.x = 'uniprotid', by.y = 'Uniprot')
head(proteome_df)
# make a dataframe and retrieve sequences using the fasta files of the human proteome
hpa_data = merge(hpa_subcell[which(hpa_subcell$localization %in% c('only_cytoplasmic', 'only_nuclear')),c('ENSG','Gene','Uniprot','localization')], proteome_df, by.x = 'Uniprot', by.y = 'uniprotid')
# remove rows containing any non-canonical amino acids (e.g. U)
passing_rows = which(sapply(hpa_data$aa, function(aa) all(unlist(strsplit(aa, '')) %in% c('R', 'H', 'K', 'D', 'E', 'S', 'T', 'N', 'Q', 'C', 'G', 'P', 'A', 'V', 'I', 'L', 'M', 'F', 'Y', 'W'))))
hpa_data = hpa_data[passing_rows,]
colnames(hpa_data) = c('uniprotid', 'ENSG', 'Gene', 'localization', 'aa')
# make predictions
hpa_data_prediction_df <- compute_prediction_df(pdata = hpa_data, score_matrix = score_matrix, ndata = NULL)
hpa_data_prediction_df <- merge(hpa_data_prediction_df, hpa_data[,c('uniprotid', 'Gene')], by.x = 'seq_name', by.y = 'uniprotid')
hpa_data_prediction_df$position_weighted_score = stats::predict(glm_position_based_XV$model_all_data, hpa_data_prediction_df)
# return the highest score for each protein
hpa_data$high_scores = sapply(hpa_data$uniprotid, function(x) {
max(hpa_data_prediction_df[which(hpa_data_prediction_df$seq_name == x),'position_weighted_score'])
})
hpa_data = hpa_data[order(hpa_data$high_scores, decreasing = T),]; hpa_data$high_score_rank = seq(1,nrow(hpa_data))
hpa_data$rank_bin = as.factor(cut(hpa_data$high_score_rank, 30, dig.lab=4 ))
wilcox.test(x = hpa_data[which(hpa_data$localization == 'only_nuclear'),'high_scores'],
y = hpa_data[which(hpa_data$localization == 'only_cytoplasmic'),'high_scores'])
hpa_data$Localization = 'Nuclear'
hpa_data[which(hpa_data$localization == 'only_cytoplasmic'),'Localization'] = 'Cytoplasmic'
ggplot(hpa_data, aes(x = Localization, y = high_scores, fill = Localization)) + geom_boxplot() +
theme_classic() +
theme(axis.text.x = element_text(size = 10),
axis.text.y = element_text(size = 10),
axis.title = element_text(size = 14)) +
scale_fill_manual(values = c('#d73027', '#4575b4')) +
ylab('Max 11-mer score') + xlab('Localization') +
guides(fill = FALSE)
hpa_proc = pROC::roc(hpa_data$localization == 'only_nuclear', hpa_data$high_scores)
hpa_proc_df = melt(data.frame(cutoff = hpa_proc$thresholds,
sens = hpa_proc$sensitivities,
spec = hpa_proc$specificities),
id.vars = 'cutoff')
ggplot(hpa_proc_df, aes(x = cutoff, y = value, color = variable)) + geom_line()
hpa_proc_df = data.frame(cutoff = hpa_proc$thresholds,
sens = hpa_proc$sensitivities,
spec = hpa_proc$specificities))
hpa_proc_df = data.frame(cutoff = hpa_proc$thresholds,
sens = hpa_proc$sensitivities,
spec = hpa_proc$specificities)
head(hpa_proc_df)
ggplot(hpa_proc_df, aes(x = 1-sens, y = spec, color = variable)) + geom_line()
ggplot(hpa_proc_df, aes(x = 1-sens, y = spec)) + geom_line()
ggplot(hpa_proc_df, aes(x = 1-sens, y = spec)) + geom_line() + abline(linetype = 'dashed')
ggplot(hpa_proc_df, aes(x = 1-sens, y = spec)) + geom_line() + abline(linetype = 'dashed')
ggplot(hpa_proc_df, aes(x = 1-sens, y = spec)) + geom_line() + abline(linetype = 'dashed')
ggplot(hpa_proc_df, aes(x = 1-sens, y = spec)) + geom_line() #+ abline(linetype = 'dashed')
ggplot(hpa_proc_df, aes(x = 1-sens, y = spec)) + geom_line() + geom_abline(linetype = 'dashed')
ggplot(hpa_proc_df, aes(x = 1-sens, y = spec)) + geom_line() + geom_abline(linetype = 'dashed') + theme_classic()
save.image('temp3.RData')
